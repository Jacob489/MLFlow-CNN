{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd072b9f-f3c6-4047-b7c2-2a0c9bf4347f",
   "metadata": {},
   "source": [
    "# Import Standard Libraries and Set Up CUDA Environment\n",
    "In this cell, we import essential Python libraries and determine the paths to the CUDA libraries based on the conda environment. By setting the environment variables (CUDA_PATH, LD_LIBRARY_PATH, and XLA_FLAGS), we ensure that TensorFlow can locate and use the GPU libraries for optimal performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c792d9-507b-444f-bb71-15aa6486c487",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import getpass\n",
    "from datetime import datetime\n",
    "\n",
    "# Get conda environment path and determine CUDA library paths\n",
    "conda_env_path = os.path.dirname(os.path.dirname(sys.executable))\n",
    "cuda_path = os.path.join(conda_env_path, \"lib\")\n",
    "\n",
    "# Set environment variables to help locate CUDA libraries for TensorFlow\n",
    "os.environ['CUDA_PATH'] = conda_env_path\n",
    "os.environ['LD_LIBRARY_PATH'] = f\"{cuda_path}:{os.environ.get('LD_LIBRARY_PATH', '')}\"\n",
    "os.environ['XLA_FLAGS'] = f\"--xla_gpu_cuda_data_dir={conda_env_path}\"\n",
    "\n",
    "print(f\"Set CUDA_PATH to: {conda_env_path}\")\n",
    "print(f\"Set XLA_FLAGS to: {os.environ['XLA_FLAGS']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3049e8e4-cfcf-4c44-9738-f975eea81f95",
   "metadata": {},
   "source": [
    "# Import Machine Learning Libraries and Modules\n",
    "\n",
    "This cell loads the key libraries required for building and training the model. These include TensorFlow (and related modules), MLflow for tracking experiments, and additional libraries for data processing, visualization, and command-line argument parsing. Utility functions from photoz_utils and DataMakerPlus are also imported for custom data handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd10b51-0127-4b61-8e70-4efc2d5fadb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import keras\n",
    "import tensorboard\n",
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Input, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "import argparse\n",
    "\n",
    "# Import utility functions for handling data and domain-specific processing\n",
    "from photoz_utils import *\n",
    "from DataMakerPlus import *\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b36891-b450-4e65-880c-75ca01d7a1d6",
   "metadata": {},
   "source": [
    "# Configure GPU Settings\n",
    "This cell checks for available GPUs and enables memory growth. Enabling memory growth ensures that TensorFlow only allocates as much GPU memory as needed, rather than grabbing all available memory. This is especially useful when running multiple experiments on the same machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac717455-312c-4bb3-a4fc-5cf0dfcaf1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available GPUs and enable memory growth to prevent TensorFlow from allocating all GPU memory at once\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"Found {len(gpus)} GPU(s)\")\n",
    "    for i, gpu in enumerate(gpus):\n",
    "        print(f\"  GPU {i}: {gpu}\")\n",
    "        try:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            print(f\"  Memory growth enabled for GPU {i}\")\n",
    "        except RuntimeError as e:\n",
    "            print(f\"  Error setting memory growth: {e}\")\n",
    "else:\n",
    "    print(\"No GPUs found. Please check your TensorFlow installation.\")\n",
    "    sys.exit(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f8eb88-4700-42c6-9211-074cb219d31f",
   "metadata": {},
   "source": [
    "# Parse Command-Line Arguments\n",
    "This cell utilizes the argparse module to define and parse command-line arguments. These arguments allow you to easily customize training parameters (such as image size, number of epochs, batch size, and learning rate) and MLflow experiment details (experiment and run names) without modifying the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e021af2-f818-4724-b587-85da48991911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define command-line arguments to configure hyperparameters and experiment details\n",
    "parser = argparse.ArgumentParser(description=\"Train CNN for redshift estimation with MLFlow tracking.\")\n",
    "parser.add_argument('--image_size', type=int, default=64, choices=[64, 127], help=\"Image size (default: 64)\")\n",
    "parser.add_argument('--epochs', type=int, default=200, help=\"Number of training epochs (default: 200)\")\n",
    "parser.add_argument('--batch_size', type=int, default=256, help=\"Batch size (default: 256)\")\n",
    "parser.add_argument('--learning_rate', type=float, default=0.0001, help=\"Learning rate (default: 0.0001)\")\n",
    "parser.add_argument('--experiment_name', type=str, default=\"Galaxy_CNN_Redshift_Estimation\", help=\"MLflow experiment name\")\n",
    "parser.add_argument('--run_name', type=str, default=None, help=\"MLflow run name (default: auto-generated)\")\n",
    "parser.add_argument('--gpu_id', type=int, default=0, help=\"GPU ID to use (default: 0)\")\n",
    "args = parser.parse_args()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d5e7ba-cac8-4782-86c4-18fedd720291",
   "metadata": {},
   "source": [
    "# GPU Selection for Multi-GPU Systems\n",
    "\n",
    "When multiple GPUs are detected, this cell sets the CUDA_VISIBLE_DEVICES environment variable to select the specific GPU (as given by the command-line argument). This ensures that the training runs on the intended GPU, which can be important for resource allocation and reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d14ada-41ce-484a-bf6a-33f4c7434def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If multiple GPUs are available, use the specified GPU from the command-line argument\n",
    "if len(gpus) > 1:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.gpu_id)\n",
    "    print(f\"Using GPU {args.gpu_id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e9a2b0-11ad-4808-93d2-affd0828fcda",
   "metadata": {},
   "source": [
    "# Confirm GPU Usage for Training\n",
    "This cell uses TensorFlow’s device context to verify that a GPU is available for training. It confirms that the code is running on a GPU device (here assumed to be /GPU:0), which is critical for taking advantage of hardware acceleration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1928327-0e6f-4f10-8ffd-c87eabbc6859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm that TensorFlow can access the GPU by explicitly setting the device\n",
    "with tf.device('/GPU:0'):\n",
    "    print(\"GPU is available and will be used for training\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0012e1da-53d1-47b1-81c1-6efd04e6fcf5",
   "metadata": {},
   "source": [
    "# MLflow Tracking Setup\n",
    "\n",
    "This cell configures MLflow for experiment tracking. It sets the tracking URI to a shared directory (/shared/mlruns) and initializes (or creates) the MLflow experiment with the name specified via the command-line argument. This integration allows you to log hyperparameters, metrics, and artifacts during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8474b9f7-5853-4e53-86c8-bd6d47212b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup MLflow tracking directory and experiment\n",
    "mlruns_dir = \"/shared/mlruns\"\n",
    "os.makedirs(mlruns_dir, exist_ok=True)\n",
    "mlflow.set_tracking_uri(f\"file://{mlruns_dir}\")\n",
    "mlflow.set_experiment(args.experiment_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb62f52-709b-44a9-aa87-0fc013f26f6a",
   "metadata": {},
   "source": [
    "# Create Directories for Checkpoints and Logs\n",
    "\n",
    "In this cell, directories are created to store model checkpoints and training logs. Organizing these outputs helps manage experiment artifacts and makes it easier to review model performance later. The checkpoints are particularly important as they capture the model's state at a given time, which MLflow logs as an artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92eb1af0-9fc8-4287-bdd6-c264e6983fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base directory for experiments and create directories for checkpoints and logs\n",
    "base_dir = \"/shared/experiments\"\n",
    "checkpoint_dir = os.path.join(base_dir, \"MLCheckpoints\")\n",
    "log_dir = os.path.join(base_dir, \"MLlogs\")\n",
    "\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "os.makedirs(log_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ba5ced-55b2-4b47-87da-7c08c679bf30",
   "metadata": {},
   "source": [
    "# Define Hyperparameters and Data Paths\n",
    "\n",
    "This cell sets the hyperparameters for the model and training process using the parsed command-line arguments. It also stores these values in a dictionary (hparams) which will later be logged in MLflow for reproducibility. In addition, file paths for the training, validation, and test datasets are defined and checked for existence to avoid runtime errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2ec87f-0af6-42d9-9c7e-3eb66a649805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters and dataset file paths\n",
    "image_size = args.image_size\n",
    "BATCH_SIZE = args.batch_size\n",
    "NUM_EPOCHS = args.epochs\n",
    "LEARNING_RATE = args.learning_rate\n",
    "NUM_DENSE_UNITS = 200\n",
    "Z_MAX = 4\n",
    "DATA_FORMAT = 'channels_first'\n",
    "\n",
    "# Store hyperparameters in a dictionary for MLflow logging\n",
    "hparams = {\n",
    "    'image_size': image_size,\n",
    "    'num_dense_units': NUM_DENSE_UNITS,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'num_epochs': NUM_EPOCHS,\n",
    "    'learning_rate': LEARNING_RATE,\n",
    "    'z_max': Z_MAX,\n",
    "    'data_format': DATA_FORMAT\n",
    "}\n",
    "\n",
    "# Dataset file paths for training, validation, and testing\n",
    "TRAIN_PATH = '/shared/astrodata/5x64x64_training_with_morphology.hdf5'\n",
    "VAL_PATH = '/shared/astrodata/5x64x64_validation_with_morphology.hdf5'\n",
    "TEST_PATH = '/shared/astrodata/5x64x64_testing_with_morphology.hdf5'\n",
    "\n",
    "# Verify that each dataset exists before proceeding\n",
    "for path in [TRAIN_PATH, VAL_PATH, TEST_PATH]:\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"Dataset not found: {path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50065ed-729f-4b06-803e-787c3b9b65e6",
   "metadata": {},
   "source": [
    "# Define Unique Checkpoint File Naming\n",
    "\n",
    "This cell creates a unique file name for the model checkpoint by incorporating the current user's name and a timestamp. This practice ensures that each training run’s checkpoint is uniquely identifiable, which is useful when tracking and comparing multiple experiments in MLflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacb39f2-ad1b-4df4-b5a6-4e04e9a1a5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a unique checkpoint filepath based on username and current timestamp\n",
    "username = getpass.getuser()\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "checkpoint_filepath = os.path.join(checkpoint_dir, f\"{username}_cp_{timestamp}.weights.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81f946f-7da8-4ae9-9762-03bb37cd9bdd",
   "metadata": {},
   "source": [
    "# Define the Model Architecture \n",
    "\n",
    "This cell defines the function create_model(), which constructs a Keras model with two input branches. One branch (CNN) processes image data while the other (NN) handles additional numerical features. The branches are concatenated before producing the final output. The model is compiled with the Adam optimizer, mean squared error loss, and RMSE as a metric. This function encapsulates the model architecture, making it reusable in different parts of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7514db31-9207-49f1-9fd0-9fff5f3fccdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    # Define two separate inputs: one for image data (CNN branch) and one for auxiliary numeric data (NN branch)\n",
    "    input_cnn = Input(shape=(5, image_size, image_size))\n",
    "    input_nn = Input(shape=(5,))\n",
    "    \n",
    "    # CNN branch: two convolutional layers followed by max pooling\n",
    "    conv1 = Conv2D(32, kernel_size=(3, 3), activation='tanh', padding='same', data_format=DATA_FORMAT)(input_cnn)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2), data_format=DATA_FORMAT)(conv1)\n",
    "    conv2 = Conv2D(64, kernel_size=(3, 3), activation='tanh', padding='same', data_format=DATA_FORMAT)(pool1)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2), data_format=DATA_FORMAT)(conv2)\n",
    "    \n",
    "    # Flatten and process the CNN branch\n",
    "    flatten = Flatten()(pool2)\n",
    "    dense1 = Dense(512, activation='tanh')(flatten)\n",
    "    dense2 = Dense(128, activation='tanh')(dense1)\n",
    "    dense3 = Dense(32, activation='tanh')(dense2)\n",
    "    \n",
    "    # NN branch: process the auxiliary input through dense layers\n",
    "    hidden1 = Dense(NUM_DENSE_UNITS, activation=\"relu\")(input_nn)\n",
    "    hidden2 = Dense(NUM_DENSE_UNITS, activation=\"relu\")(hidden1)\n",
    "    \n",
    "    # Concatenate features from both branches and output a single prediction\n",
    "    concat = Concatenate()([dense3, hidden2])\n",
    "    output = Dense(1)(concat)\n",
    "    \n",
    "    # Compile the model with Adam optimizer and mean squared error loss; RMSE is tracked as a metric\n",
    "    model = Model(inputs=[input_cnn, input_nn], outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=LEARNING_RATE), loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d18183c-0f34-4228-a0b4-a8eab5e66f14",
   "metadata": {},
   "source": [
    "# Define the MLflow Callback for Logging Metrics\n",
    "\n",
    "Here we create a custom Keras callback—MLflowCallback—that logs each metric (e.g., loss and RMSE) to MLflow at the end of every epoch. This integration is crucial for tracking model performance over time and enables detailed experiment logging and later analysis via MLflow’s UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9166704-69a1-4ce8-bfee-a4494157e447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom callback to log training metrics to MLflow at the end of each epoch\n",
    "class MLflowCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        for name, value in logs.items():\n",
    "            mlflow.log_metric(name, value, step=epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d22cdc-a16f-40f4-9744-282bba21fb8d",
   "metadata": {},
   "source": [
    "# Define the Training Function with MLflow Integration\n",
    "\n",
    "This cell defines the train_model_with_mlflow() function, which encapsulates the full training process:\n",
    "\n",
    "* MLflow Integration: Starts an MLflow run, logs hyperparameters, and sets a run tag.\n",
    "* Model Training: Initializes the model, sets up data generators, and begins training while the custom MLflow callback logs metrics.\n",
    "* Artifact Logging: After training, the model is saved and the checkpoint is logged as an artifact in MLflow.\n",
    "* Evaluation: The model is evaluated on a test dataset, and performance metrics (loss and RMSE) are logged. This comprehensive integration with MLflow ensures that every run is tracked, reproducible, and easily comparable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcadf2b3-2b85-4b72-aa19-d21200d2df87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_with_mlflow():\n",
    "    # Generate a run name if not provided, which includes key hyperparameter values and the username\n",
    "    run_name = args.run_name or f\"GalaxyCNN_Size{image_size}_Batch{BATCH_SIZE}_LR{LEARNING_RATE}_Epochs{NUM_EPOCHS}_{username}\"\n",
    "    \n",
    "    # Start an MLflow run to track this experiment\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        mlflow.set_tag(\"username\", username)\n",
    "        mlflow.log_params(hparams)  # Log all hyperparameters\n",
    "        \n",
    "        # Create and compile the model\n",
    "        model = create_model()\n",
    "        \n",
    "        # Create data generators for training and validation\n",
    "        train_gen = HDF5DataGenerator(TRAIN_PATH, mode='train', batch_size=BATCH_SIZE)\n",
    "        val_gen = HDF5DataGenerator(VAL_PATH, mode='train', batch_size=BATCH_SIZE)\n",
    "        \n",
    "        # Train the model with the MLflow callback to log metrics after each epoch\n",
    "        model.fit(train_gen, epochs=NUM_EPOCHS, validation_data=val_gen, callbacks=[MLflowCallback()], verbose=1)\n",
    "        \n",
    "        # Save the model checkpoint and log it as an MLflow artifact\n",
    "        model.save(checkpoint_filepath)\n",
    "        mlflow.log_artifact(checkpoint_filepath)\n",
    "        \n",
    "        # Evaluate the model on the test set and log the performance metrics\n",
    "        test_gen = HDF5DataGenerator(TEST_PATH, mode='test', batch_size=BATCH_SIZE)\n",
    "        test_loss, test_rmse = model.evaluate(test_gen, verbose=1)\n",
    "        mlflow.log_metric(\"test_loss\", test_loss)\n",
    "        mlflow.log_metric(\"test_rmse\", test_rmse)\n",
    "\n",
    "        print(f\"Training complete. MLflow Run ID: {mlflow.active_run().info.run_id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362db322-a934-461a-9fc0-4a3b7d471aad",
   "metadata": {},
   "source": [
    "# Main Execution Guard \n",
    "\n",
    "The final cell checks if the script is being run as the main program. If so, it calls the training function. This structure allows the notebook to be executed as a standalone script while keeping the code modular and easy to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f00714c-5217-4e6e-af2b-d065930b91ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train_model_with_mlflow()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
